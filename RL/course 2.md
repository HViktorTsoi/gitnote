Markov Process with Reward and action
1. Markov过程: 由(状态,状态转移概率方程)构成
![Screenshot from 20190525 174358.png](0)
2. reward: 每个状态有一个reward(即每一个状态的reward是广播到其入边上的权值)
![Screenshot from 20190525 174513.png](1)
3. return: 是第t步的全部折扣reward
![Screenshot from 20190525 174538.png](2)
